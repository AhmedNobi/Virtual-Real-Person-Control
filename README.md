# Virtual-Real-Person-Control
We study the problem of image-to-video synthesis, whose goal is to learn a mapping function from an input source video to an output photorealistic video that precisely depicts the content of the source video.

# Example Generating video
The video in the center shows the Source driving video. the image on the left side is the source image that wants it to do a specific motion. the Video on the Right shows output generating fake video after Mapping motion from the source video to the source image.
![image](example.PNG)

# Dataset Used
- The VoxCeleb dataset is a face dataset of 22496 videos, extracted from YouTube videos, obtain 12331 training videos and 444 test videos, with lengths varying from 64 to 1024 frames.
- The Tai-chi HD dataset, a body dataset of 280 videos collected from YouTube. We use 252 videos for training and 28 for testing.

# Colab Demo
prepared a gui-demo for the google-colab see: demo.ipynb. To run press Open In Colab button.

